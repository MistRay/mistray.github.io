---
layout:     post                    # 使用的布局（不需要改）
title:      canal同步体系        # 标题 
subtitle:   canal  #副标题
date:       2020-06-05          # 时间
author:     MistRay                      # 作者
# header-img: img/post-bg-7.jpg 这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - canal
    - adapter
---
## 前言

写这篇文章的契机是工作中遇到的一个场景。生产环境中有一个数据量巨大（10亿级）且已经用`Shardingjdbc`做了分表的多表数据集。
分表逻辑是这样的，每天一张表，当天产生的数据录入当天的表内（例：2020年6月5日的数据录入到table_20200605表中）。
其中有一个查询需要做多天数据的聚合，之前的方案是通过`Shardingjdbc`做多表聚合，数据量大了之后，效率极低，
低到已经无法使用的程度，只能暂时在业务上限制，对多只能跨两张表查询。

经过了一段时间的技术选型，我们决定核心业务依然依赖MySQL，但是列表查询使用ElasticSearch作为查询组件。
这时又产生了一个新的问题，要如何从MySQL把数据实时同步到ES？

## 方案对比

在查阅了大量资料后，初步选择确定在了**elasticsearch-jdbc**,**go-mysql-elasticsearch**,**logstash-input-jdbc**以及**canal**
这四个同步方案。我对这几个工具做了横向对比。

| 插件名称           | 优点                                          | 缺点                                                |
| ---------------------- | ----------------------------------------------- | ----------------------------------------------------- |
| elasticsearch-jdbc     | 泛用度比较高,社区活跃                 | 不能实现同步删除操作.通过查询做同步,对MySQL吞吐有影响 |
| go-mysql-elasticsearch | 通过binlog做同步,能同步增删改查     | 经测试同步效率较低                                 |
| logstash-input-jdbc    | 为logstash的一部分,易用性较高         | 不能实现同步删除操作.通过查询做同步,对MySQL吞吐有影响 |
| canal                  | 通过binlog做同步,能实现增删改查,效率高,功能多样 | 学习成本较高,在没有技术积累时无法快速投入使用，顺序消费场景下，消费者横向扩展比较麻烦 |

最终，我们确定了使用canal作为MySQL增量数据的同步方案。

## canal

### canal是什么
![canal](/img/post_img/post_2020_06_05_01canal.png)

> canal [kə'næl]，译意为水道/管道/沟渠，主要用途是基于 MySQL 数据库增量日志解析，提供增量数据订阅和消费
   早期阿里巴巴因为杭州和美国双机房部署，存在跨机房同步的业务需求，实现方式主要是基于业务 trigger 获取增量变更。从 2010 年开始，
   业务逐步尝试数据库日志解析获取增量变更进行同步，由此衍生出了大量的数据库增量订阅和消费业务。

### canal工作原理
canal 模拟 MySQL slave 的交互协议，伪装自己为 MySQL slave ，向 MySQL master 发送dump 协议
MySQL master 收到 dump 请求，开始推送 binary log 给 slave (即 canal )
canal 解析 binary log 对象(原始为 byte 流)

### canal的重要版本
截止到我写这篇文章的时候，canal的最新稳定版是1.1.4，还无法支撑MySQL8.0。在已经发布的1.1.5-alpha-1版本中，
canal已经可以支持拉取MySQL8.0的binlog，canal-adapter也支持了对ES7.X版本进行同步，所以未来可期。

### canal的组件
核心组件有两个，canal-server和canal-client（以下简称server和client）。server伪装成MySQL的slave，拉取binlog，
经过处理后，发送给client，在client接收到已经结构化的数据后，可以根据自己的需求对数据做处理，
不管是要同步到ES，HBase，Hive都是可以的。

#### canal-adapter
client需要使用者自己实现，虽然官方提供了例子，但其实大家的需求是大同小异的，为了避免重复造轮子，
canal还提供了一个官方实现功能极强的client，名字叫canal-adapter（以下简称adapter）。canal配合adapter基本可以实现大部分非定制化增量数据同步。
最新版的adapter内部还使用了SPI这种黑魔法，源码读起来可能会很迷茫。还有消息顺序消费的方案也做的比较有意思。
这里就不展开了，后面会专门写一篇文章来分析这部分。

## 同步方案

![同步方案](/img/post_img/post_2020_06_05_02同步方案.png)

在这不详细讨论canal的集群方式，[wiki](https://github.com/alibaba/canal/wiki/AdminGuide)已经写的很清晰了。
这里着重讨论一下canal-adapter的分片，这部分wiki写的不是很清楚。adapter共有四种模式，tpc，rocketMQ，kafka，rabbitMQ。
除开tcp直连server外，剩下三种都使用MQ做中转，做到了server和adapter解耦。

当然，在上面的那种模式下，如果某台adapter宕机了以后，其他的adapter是不能把发给它的消息给接过去的，因为数据是做了分片或者映射的。
在使用了MQ做中转的情况下，adapter可以根据topic做分片，每个adapter仅接收对应的一个或几个topic的消息，然后做顺序处理。
canal当然也支持按正则映射或者hash的方式发送消息到不同的topic。


### 为什么MySQL只能使用row模式才可以同步
我在刚接触到adapter的时候有一个疑问，为什么canal只能同步row模式的binlog？
MySQL的binlog是逻辑日志，也就是消费端是要保证绝对有序，才能正确的消费，否则就会产生数据不一致的情况。
首先，MySQL的binlog总共有三种模式，row，statement，mixed。  

在row模式下，binlog中可以不记录执行的sql语句的上下文相关的信息，仅仅只需要记录那一条记录被修改了，修改成什么样了。

statement模式由于记录的只是执行语句，为了这些语句能在slave上正确运行，因此还必须记录每条语句在执行的时候的一些相关信息，
以保证所有语句能在slave得到和在master端执行时候相同的结果。

使用statement模式会大大增加解析的复杂度，试想你写了一条特别复杂的删除语句，可能你要同步的目标数据源根本就没有这么强的聚合功能，这个时候你就无计可施了。


## 总结
canal-server是将自己伪装成MySQL的slave，从master拉取binlog，结构化解析的工具。  
canal-client是将canal-server拉取到binlog进行解析，深度定制化（因为要自己写）。  
canal-adapter是canal官方提供的通用client解决方案，可以解决大部分的增量数据迁移场景。  




## Reference
[canal](https://github.com/alibaba/canal)

## 转载

本文遵循 [CC 4.0 by-sa](https://creativecommons.org/licenses/by-sa/4.0/) 版权协议,转载请附上原文出处链接和本声明。